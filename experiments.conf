# Word embeddings.
glove_300d {
  path = glove.840B.300d.txt
  size = 300
  format = txt
  lowercase = false
}
glove_300d_filtered {
  path = 00data/00_orig/glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}
turian_50d {
  path = 00helper_files/turian.50d.txt
  size = 50
  format = txt
  lowercase = false
}

# Compute clusters.
nlp {
  addresses {
    ps = [nlp2:2222]
    worker = [n01:2222, n02:2222, n03:2222, n04:2222, n05:2222, n07:2222, n08:2222, n09:2222, n10:2222, n11:2222, n12:2222, n13:2222, n14:2222, n15:2222, n16:2222]
  }
  gpus = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
}
appositive {
  addresses {
    ps = [localhost:2222]
    worker = [localhost:2223, localhost:2224]
  }
  gpus = [0, 1]
}

# Main configuration.
best {
  # Computation limits.
  max_antecedents = 250
  max_training_sentences = 50
  mention_ratio = 0.4

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  char_vocab_path = "00data/00_orig/char_vocab.english.txt"
  embeddings = [${glove_300d_filtered}, ${turian_50d}]
  lstm_size = 200
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_mention_width = 10
  use_metadata = true
  use_features = true
  model_heads = true

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100

  # Other.
  # train_path = train.english.jsonlines
  # eval_path = dev.english.jsonlines
  # conll_eval_path = dev.english.v4_auto_conll

  train_path = 00data/00_orig/train.english.jsonlines
  eval_path = 00data/00_orig/dev.english.jsonlines
  conll_eval_path = 00data/00_orig/dev.english.v4_auto_conll


  genres = [bc, bn, mz, nw, pt, tc, wb]
  eval_frequency = 1000
  report_frequency = 100
  log_root = logs
  cluster = ${appositive}

  stopping_criteria = 10000
}

# Multiple full models for ensembling.
best0 = ${best}
best1 = ${best}
best2 = ${best}
best3 = ${best}
best4 = ${best}

# Ablations.
glove = ${best} {
  embeddings = [${glove_300d_filtered}]
}
turian = ${best} {
  embeddings = [${turian_50d}]
}
nochar = ${best} {
  char_embedding_size = -1
}
nometa = ${best} {
  use_metadata = false
}
noheads = ${best} {
  model_heads = false
}
nofeatures = ${best} {
  use_features = false
}

# For evaluation. Do not use for training (i.e. only for decoder.py, ensembler.py, visualize.py and demo.py). Rename `best0` directory to `final`.
final = ${best} {
  embeddings = [${glove_300d}, ${turian_50d}]
  eval_path = test.english.jsonlines
  conll_eval_path = test.english.v4_gold_conll
}

# ---------------------------------------------------------------------------------------------
# MINI 
# ---------------------------------------------------------------------------------------------
glove_300d_filtered_mini {
  path = 00data/05_mini/glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}
mini = ${best} {
  # New features
  use_pos_tag = true
  use_ner_g = false
  use_ner_phi = false
  use_categories = false

  pos_tag_path = 00helper_files/pos_tag_list.txt
  ner_tag_path = 00helper_files/ner_tag_list.txt
  categories_path = 00helper_files/categories_list.txt

  embeddings = [${glove_300d_filtered_mini}, ${turian_50d}]
  char_vocab_path = "00data/05_mini/char_vocab.english.txt"

  train_path = 00data/05_mini/train.english.jsonlines
  eval_path = 00data/05_mini/dev.english.jsonlines
  conll_eval_path = 00data/05_mini/dev.english.v4_auto_conll
  genres = [bc, bn, mz, nw, pt, tc, wb]
  eval_frequency = 1000
  report_frequency = 100
  log_root = logs
  cluster = ${appositive}

  stopping_criteria = 100
}

mini_phi = ${mini} {
  use_ner_phi = true
}

mini_eldar = ${mini}
mini_none = ${mini}
mini_gpu = ${mini}

mini_categories = ${mini}{
  use_categories = true
}

# ---------------------------------------------------------------------------------------------
# MOD
# using ORIG's filtered glove
# ---------------------------------------------------------------------------------------------
mod = ${best} {
  # New features
  use_pos_tag = false
  use_ner_g = false
  use_ner_phi = false
  use_categories = false

  pos_tag_path = 00helper_files/pos_tag_list.txt
  ner_tag_path = 00helper_files/ner_tag_list.txt
  categories_path = 00helper_files/categories_list.txt

  embeddings = [${glove_300d_filtered}, ${turian_50d}]
  char_vocab_path = "00data/01_mod/char_vocab.english.txt"

  train_path = 00data/01_mod/train.english.jsonlines
  #eval_path = 00data/01_mod/dev.english.jsonlines
  #conll_eval_path = 00data/01_mod/dev.english.v4_auto_conll
  eval_path = 00data/01_mod/testv9.english.jsonlines
  conll_eval_path = 00data/01_mod/test.english.v9_auto_conll_2
  genres = [bc, bn, mz, nw, pt, tc, wb]
  eval_frequency = 1000
  report_frequency = 100
  log_root = logs
  cluster = ${appositive}

  stopping_criteria = 20000
}

mod_pos = ${mod} {
  use_pos_tag = true
}

mod_phi = ${mod} {
  use_ner_phi = true
}

mod_g = ${mod}{
  use_ner_g = true
  stopping_criteria = 7000
}

mod_pos_phi = ${mod_pos} {
  use_ner_phi = true
}

mod_categories = ${mod}{
  use_categories = true
}

# ---------------------------------------------------------------------------------------------
# NO_PT
# ---------------------------------------------------------------------------------------------
glove_300d_filtered_no_pt {
  path = 00data/02_no_pt/glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}

no_pt = ${best} {
  # New features
  use_pos_tag = false
  use_ner_g = false
  use_ner_phi = false
  
  pos_tag_path = 00helper_files/pos_tag_list.txt
  ner_tag_path = 00helper_files/ner_tag_list.txt
  categories_path = 00helper_files/categories_list.txt

  embeddings = [${glove_300d_filtered_no_pt}, ${turian_50d}]
  char_vocab_path = "00data/02_no_pt/char_vocab.english.txt"

  train_path = 00data/02_no_pt/train.english.jsonlines
  #eval_path = 00data/02_no_pt/dev.english.jsonlines
  #conll_eval_path = 00data/02_no_pt/dev.english.v4_auto_conll
  eval_path = 00data/02_no_pt/test.english.jsonlines
  conll_eval_path = 00data/02_no_pt/test.english.v4_gold_conll
  genres = [bc, bn, mz, nw, pt, tc, wb]
  eval_frequency = 1000
  report_frequency = 100
  log_root = logs
  cluster = ${appositive}

  stopping_criteria = 20000
}

no_pt_pos = ${no_pt} {
  use_pos_tag = true
}

no_pt_phi = ${no_pt} {
  use_ner_phi = true
}

no_pt_g = ${no_pt} {
  use_ner_g = true
  stopping_criteria = 15000
}

no_pt_pos_phi = ${no_pt_pos} {
  use_ner_phi = true
}

# ---------------------------------------------------------------------------------------------
# NO_WB
# ---------------------------------------------------------------------------------------------
glove_300d_filtered_no_wb {
  path = 00data/03_no_wb/glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}

no_wb = ${best} {
  # New features
  use_pos_tag = false
  use_ner_g = false
  use_ner_phi = false
  pos_tag_path = 00helper_files/pos_tag_list.txt
  ner_tag_path = 00helper_files/ner_tag_list.txt
  categories_path = 00helper_files/categories_list.txt

  embeddings = [${glove_300d_filtered_no_wb}, ${turian_50d}]
  char_vocab_path = "00data/03_no_wb/char_vocab.english.txt"

  train_path = 00data/03_no_wb/train.english.jsonlines
  #eval_path = 00data/03_no_wb/dev.english.jsonlines
  #conll_eval_path = 00data/03_no_wb/dev.english.v4_auto_conll
  eval_path = 00data/03_no_wb/test.english.jsonlines
  conll_eval_path = 00data/03_no_wb/test.english.v4_gold_conll
  genres = [bc, bn, mz, nw, pt, tc, wb]
  eval_frequency = 1000
  report_frequency = 100
  log_root = logs
  cluster = ${appositive}

  stopping_criteria = 10000
}

no_wb_pos = ${no_wb} {
  use_pos_tag = true
}

no_wb_phi = ${no_wb} {
  use_ner_phi = true
}

no_wb_g = ${no_wb} {
  use_ner_g = true
  stopping_criteria = 12000
}

no_wb_pos_phi = ${no_wb_pos} {
  use_ner_phi = true
}
